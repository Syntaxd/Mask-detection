{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Importing all libraries')\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import cv2, IPython, PIL, time\n",
    "from io import BytesIO\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator (\n",
    "            rescale = 1./255, \n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            )\n",
    "images_dir = './New Masks Dataset/'\n",
    "print('Files found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: ./New Masks Dataset/Train\n",
      "Found 600 images belonging to 2 classes.\n",
      "Test set: ./New Masks Dataset/Test\n",
      "Found 111 images belonging to 2 classes.\n",
      "Validation set :./New Masks Dataset/Validation\n",
      "Found 306 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# load the data using data generators\n",
    "print('Training set: ' + images_dir + 'Train')\n",
    "train_generator  =    datagen.flow_from_directory(\n",
    "                             images_dir + 'Train',\n",
    "                             seed=42,\n",
    "                             target_size = (200,200),\n",
    "                             batch_size = 64 ,               \n",
    "                             class_mode = 'binary',\n",
    "                            )\n",
    "\n",
    "print('Test set: ' + images_dir + 'Test')\n",
    "test_generator = datagen.flow_from_directory(\n",
    "                             images_dir + 'Test' ,\n",
    "                             seed=42, \n",
    "                             target_size = (200,200),\n",
    "                             batch_size = 64 ,               \n",
    "                             class_mode = 'binary',\n",
    "                            )\n",
    "\n",
    "print('Validation set :' + images_dir + 'Validation')\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "                             images_dir + 'Validation' ,\n",
    "                             seed=42, \n",
    "                             target_size = (200,200),\n",
    "                             batch_size = 64 ,               \n",
    "                             class_mode = 'binary',\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model defnined\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(32,(3,3),input_shape=(200,200,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#The first CNN layer followed by Relu and MaxPooling layers\n",
    "\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#The second convolution layer followed by Relu and MaxPooling layers\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "#Flatten layer to stack the output convolutions from second convolution layer\n",
    "model.add(Dense(128,activation='relu'))\n",
    "#Dense layer of 128 neurons\n",
    "model.add(Dense(2,activation='softmax'))\n",
    "#The Final layer with two outputs for two categories\n",
    "\n",
    "# model.compile(loss='sparse_categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
    "              metrics=['accuracy'])\n",
    "print('Model defnined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3786 - accuracy: 0.8265 - val_loss: 0.2959 - val_accuracy: 0.8889\n",
      "\n",
      "Epoch 00001: saving model to Test\n",
      "Epoch 2/2\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.2229 - accuracy: 0.9119 - val_loss: 0.3455 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00002: saving model to Test\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('Test')\n",
    "\n",
    "\n",
    "H = model.fit(\n",
    "        train_generator,\n",
    "        epochs = 2,\n",
    "        validation_data = validation_generator,\n",
    "        callbacks = tf.keras.callbacks.ModelCheckpoint(filepath='Test',\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1))\n",
    "# model.save('Model/assets')\n",
    "# https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4917c316d835>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mwhat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplots\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwhat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcu\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlinewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'H' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plots = ['val_accuracy','val_loss', 'accuracy', 'loss']\n",
    "co = ['red','green','blue', 'orange']\n",
    "cu = 0\n",
    "for what in plots:\n",
    "    y1 = []\n",
    "    for x in H.history[what]:\n",
    "        y1.append(x)\n",
    "    plt.plot(H.epoch, y1, color=co[cu],linewidth = 1, label = what)\n",
    "    cu +=1\n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.legend() \n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_resize(image, height = None, inter = cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "    r = height / float(h)\n",
    "    dim = (int(w * r), height)\n",
    "    return cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "def image_reshape(image, dimension=200): \n",
    "    image = image_resize(image, height=dimension)\n",
    "    (h, w, c) = image.shape\n",
    "    offset = int((w-dimension)/2)\n",
    "    image = image[0:dimension, offset:dimension+offset, 0:c]\n",
    "    return image\n",
    "def get_frame(cam):\n",
    "    ret, frame = cam.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    return frame\n",
    "def array_to_image(a, fmt='jpeg'):\n",
    "    f = BytesIO()\n",
    "    PIL.Image.fromarray(a).save(f, fmt)\n",
    "    return IPython.display.Image(data=f.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "unmask"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "16 FPS"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "cam = cv2.VideoCapture(1)\n",
    "\n",
    "d = IPython.display.display(\"\", display_id=1)\n",
    "d2 = IPython.display.display(\"\", display_id=2)\n",
    "d3 = IPython.display.display(\"\", display_id=3)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        t1 = time.time()\n",
    "        frame = get_frame(cam)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = image_reshape(frame, dimension=200)\n",
    "        \n",
    "        result = model.predict(frame.reshape(1,200,200,3))\n",
    "        if result[0][0] > .5:\n",
    "            prediction = 'mask'\n",
    "        else :\n",
    "            prediction = 'unmask'\n",
    "\n",
    "        im = array_to_image(frame)\n",
    "        d.update(im)\n",
    "\n",
    "        t2 = time.time()\n",
    "\n",
    "        s = f\"\"\"{int(1/(t2-t1))} FPS\"\"\"\n",
    "        d2.update( IPython.display.HTML(prediction))\n",
    "        d3.update( IPython.display.HTML(s))\n",
    "    except KeyboardInterrupt:\n",
    "        cam.release()\n",
    "        IPython.display.clear_output()\n",
    "        print (\"Stream stopped\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "#For Predicting on single Image\n",
    "from tensorflow.keras.preprocessing import image\n",
    "# test_image = image.load_img('New Masks Dataset/Test/Mask/2300.png', target_size = (200,200,3))\n",
    "test_image = image.load_img('New Masks Dataset/Test/Non Mask/real_01081.jpg', target_size = (200,200,3))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "print(result[0])\n",
    "if result[0][0] > .5:\n",
    "    prediction = 'mask'\n",
    "else :\n",
    "    prediction = 'unmask'\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
